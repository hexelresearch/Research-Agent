{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"Arrr, Ahoy Khushwant me hearty! Yer want to talk to a pirate, eh? Alright then, I be ready fer some swashbucklin' chat! What be bringin' ye to these fair waters? Treasure huntin', sailin' the seven seas, or just lookin' fer some pirate chat?\"}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello, My Name is Khushwant\"},\n",
    "]\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44eb52548ef64c43be0cd2cc845642c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'You\\'re referring to the influential research paper \"Attention is All You Need\" by Ashish Vaswani et al., published in 2017.\\n\\nThe paper introduced the Transformer architecture, which revolutionized the field of natural language processing (NLP) and machine learning. The Transformer model was designed to address the limitations of traditional recurrent neural networks (RNNs) and convolutional neural networks (CNNs) in handling long-range dependencies and parallelization of computations.\\n\\nHere are some key findings and contributions of the paper:\\n\\n1. **Self-Attention Mechanism**: The paper proposed a self-attention mechanism, which allows the model to weigh the importance of different input elements relative to each other. This mechanism enables the model to capture long-range dependencies and relationships between input elements.\\n2. **Parallelization**: The Transformer model is parallelized, meaning that it can be computed on multiple GPUs or CPUs simultaneously, making it much faster than traditional sequential models.\\n3. **No Recurrent Connections**: Unlike RNNs, the Transformer model does not use recurrent connections, which can lead to vanishing gradients and other issues.\\n4. **No Convolutional Layers**: The Transformer model does not use convolutional layers, which can be computationally expensive and may not be effective for certain tasks.\\n\\nThe paper demonstrated the effectiveness of the Transformer model on several NLP tasks, including:\\n\\n1. **Machine Translation**: The model achieved state-of-the-art results on the WMT 2014 English-to-German translation task.\\n2. **Text Classification**: The model achieved state-of-the-art results on the GLUE benchmark, which includes several text classification tasks.\\n3. **Question Answering**: The model achieved state-of-the-art results on the SQuAD 1.1 question answering task.\\n\\nThe \"Attention is All You Need\" paper has had a significant impact on the field of NLP and machine learning, and its influence can be seen in many subsequent models and architectures, including:\\n\\n1. **BERT**: The BERT model, developed by Google, is a direct descendant of the Transformer architecture and has achieved state-of-the-art results on many NLP tasks.\\n2. **RoBERTa**: The RoBERTa model, also developed by Facebook AI, is another variant of the Transformer architecture that has achieved state-of-the-art results on many NLP tasks.\\n3. **XLNet**: The XLNet model, developed by Google, is a variant of the Transformer architecture that has achieved state-of-the-art results on many NLP tasks.\\n\\nOverall, the \"Attention is All You Need\" paper has had a profound impact on the field of NLP and machine learning, and its influence will likely be felt for many years to come.'}\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a Research Assistant Who always talk with Facts and In depth Knowledge\"},\n",
    "    {\"role\": \"user\", \"content\": \"Do you know the attention is all you need research paper\"},\n",
    "]\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=1024,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n",
    "# Check the length of the generated text\n",
    "print(len(outputs[0][\"generated_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
